{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpEx-Jd1pYlP"
   },
   "source": [
    "# CIS 5450 Homework 5: Deep Learning with Pytorch\n",
    "\n",
    "### Due Tuesday, July 22, 2025 11:59 PM EST\n",
    "\n",
    "<ins>Total Points</ins>: **100 points** (= 84 autograded + 16 manually graded)\n",
    "\n",
    "Welcome to CIS 5450 Homework 5!\n",
    "\n",
    "In this homework, we will learn more about the 'new electricity' - Deep Learning (I didn't coin this, Andrew Ng did) ! There are many cool frameworks for building deep learning models - PyTorch, Tensorflow, Theano, MxNet. Since you will be working with Big Data in this course, you need a framework that scales well. Almost all of these have a multi-gpu support built in. In this assignment, we will be building neural networks in PyTorch to solve an interesting problem.\n",
    "\n",
    "Deep learning or neural network architectures have been used to solve a multitude of problems in various different fields like vision, natural language processing. So let's take a 'deep' dive into it.\n",
    "\n",
    "\n",
    "![alt text](http://4.bp.blogspot.com/-sLgBLS3bJO8/U__Kx6PnkRI/AAAAAAAAAWM/Gz3cL5jiwTo/s320/godeeper.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhSzWDvPp030"
   },
   "source": [
    "## Why deep learning?\n",
    "\n",
    "\n",
    "*   It's coooool\n",
    "*   Everyone's talking about it. It's the foundation of almost all the 'AI' we see in the news today\n",
    "*    Deep learning unlocks the treasure trove of unstructured big data for those with the imagination to use it\n",
    "*   Deep learning models have great representational power and are 'universal approximators'\n",
    "\n",
    "\n",
    "### Deep Learning Applications:\n",
    "\n",
    "\n",
    "Deep learning is taking the world by storm.\n",
    "\n",
    "Deep learning has applications across so many industries, which is why experts think that this technology is the future of almost everything. breakthrough LLMs such as ChatGPT, Claude and Llama are deep learning models. There are truly deep learning technologies such as Video generation models, Self Driving cars, and various budding ideas that are transforming the way we live. Here are some cool applications of deep learning -\n",
    "\n",
    "Here's a neural network detecting anomalies in Chest Xrays :\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://imgur.com/HKPzrzP.jpg)\n",
    "\n",
    "Most humans can't tell that this is a case of Pleural Effusion {sounds like medical jargon to engineers like us} but this Neural Network model can detect it very well!\n",
    "\n",
    "Mask RCNNs in action for detecting objects on the road aiding a self driving vehicle's driving:\n",
    "<div>\n",
    "<img src=\"https://miro.medium.com/max/3864/1*O4wsvh0CHWjP6IrK9HI_Zg.png\", width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "Pretty cool, right? While transformers are exploding on the scene today, we will be applying CNNs, another powerful architecture, to solve a cool image classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywLp-5aPgkjm"
   },
   "source": [
    "# Libraries and Setup Jargon (Total: 1 point)\n",
    "Run the following cells to set up the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNx7mL19gsHV"
   },
   "source": [
    "Please make sure you enter your **8 digit Penn ID** in the  student ID field below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtjibtD4lvxZ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -i https://test.pypi.org/simple/ penn-grader==0.5.0\n",
    "from penngrader.grader import *\n",
    "\n",
    "#PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO\n",
    "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
    "\n",
    "STUDENT_ID =       # YOUR PENN-ID GOES HERE AS AN INTEGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1698595514148,
     "user": {
      "displayName": "Bhairavi Muralidharan",
      "userId": "11367675023261624055"
     },
     "user_tz": 240
    },
    "id": "LsfyTveqgxss",
    "outputId": "1099e12c-8c7d-4186-a548-84dfca19e062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "grader_api_url: 'https://23whrwph9h.execute-api.us-east-1.amazonaws.com/default/Grader23'\n",
    "grader_api_key: 'flfkE736fA6Z8GxMDJe2q8Kfk8UDqjsG3GVqOFOa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQaH_xAag0BG"
   },
   "outputs": [],
   "source": [
    "grader = PennGrader('config.yaml', 'cis5450_su25_HW5', STUDENT_ID, STUDENT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RY5BOTyRg4Qf"
   },
   "source": [
    "## Import the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6diQ4Pfug3uw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from google.colab import drive\n",
    "from dill.source import getsource\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq7rZTSc0xoq"
   },
   "source": [
    "## Set up GPU capabilities (1 point)\n",
    "\n",
    "The cell below sets up a CUDA device to use with torch, if available to you.\n",
    "\n",
    "**Remember to turn on the GPU for runtime in Colab**\n",
    "*   Go to Runtime -> Change runtime type --> T4-GPU (Usually this is chosen by default)\n",
    "\n",
    "In Colab, as a free-tier user you only have access to T4-GPU. There are dynamic usage limits on colab which is ~ 2 hours of GPU access everyday. Refer to the notes below for instructions on how to work with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUvWZZQE0xo8"
   },
   "source": [
    "Note that you can create a PyTorch tensor `T` that resides on the GPU using the command `T = torch.Tensor(..., device=cuda)`.\n",
    "You can also copy existing tensors to the GPU with the command `T = T.to(device)` (make sure to overwrite `T` with the result of this function call). If you do not have a GPU, these commands will still work.\n",
    "\n",
    "**NOTE 1**: The grader cell below is to check that you are using the GPU, since it is beneficial in later sections that require parallel computation on arrays (i.e., Section 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq6We15Qqak6"
   },
   "source": [
    "**NOTE 2**: It is possible that your Google Colab GPU credits may run out. In that case here are a couple of simple options to get past this:\n",
    "\n",
    "* Continue the assignment using CPU. This will be a little slower but will still work. The autograder takes points from your best submission for each cell, so as long as you get the below points once, you will get these points. **Note that Colab selects a GPU runtime by-default when you load the notebook.**\n",
    "\n",
    "* Use your personal email account. Your personal email account will have the same number of initial credits, and you can work from there by simply sharing this assignment with your personal id. Some students also choose to purchase more credits here to move even faster. **Please note that this is a quick fix and not a solution as inefficient code will lead to fast depletion of credits**\n",
    "\n",
    "If you are having GPU issues please feel free to make an Ed post or attend an Office Hour and we will help you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1698595646446,
     "user": {
      "displayName": "Bhairavi Muralidharan",
      "userId": "11367675023261624055"
     },
     "user_tz": 240
    },
    "id": "9Gvv3LVN0xo-",
    "outputId": "4f8a6960-8da7-4bd1-8dd1-56b309e83a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY\n",
    "torch.manual_seed(42) # For grading consistency\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1698595647482,
     "user": {
      "displayName": "Bhairavi Muralidharan",
      "userId": "11367675023261624055"
     },
     "user_tz": 240
    },
    "id": "ZO8Hr0MIw_KK",
    "outputId": "4892cf98-1a47-4e58-89fe-3be3ef1bac32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scjhlNsVadIi"
   },
   "outputs": [],
   "source": [
    "# Grader Cell (1 points)\n",
    "grader.grade(test_case_id = 'device', answer = str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnlOxnsy1TtK"
   },
   "source": [
    "# **Part 1:** Data Preprocessing and Preparation for Modeling in `PyTorch` (Total: 20 points)\n",
    "\n",
    "In this homework we will tackle the problem of classifying images.\n",
    "\n",
    "Specifically, we would be looking at the Modified National Institute of Standards and Technology database ([MNIST](https://en.wikipedia.org/wiki/MNIST_database)) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zn1Vfni1Tt8"
   },
   "source": [
    "<div>\n",
    "<img src=\"https://s2.loli.net/2023/03/26/GwFJhNeskzE5Ptx.webp\", width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "Diagram Reference: [Link](https://en.wikipedia.org/wiki/MNIST_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLwaiP_v1Tt9"
   },
   "source": [
    "[MNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html) dataset consists of 70,000 28x28 grayscale images in 10 classes.\n",
    "\n",
    "There are 60,000 training images and 10,000 test images.\n",
    "\n",
    "While it is good to have as much training data as possible, in order to avoid having long training time and potentially running out of GPU, we will downsample and train the model with 30,000 training images and 5,000 testing images.\n",
    "\n",
    "\n",
    "We would be using this dataset to train 3 different models:\n",
    "\n",
    "1.   Softmax Regression\n",
    "2.   Feedforward (Fully-Connected) Neural Network\n",
    "3.   Convolutional Neural Network\n",
    "\n",
    "And analyze the difference between these models by looking at the test accuracy and loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXE0i7d8SHS2"
   },
   "source": [
    "## 1.1 Pytorch Dataset and DataLoader (Total: 10 points)\n",
    "\n",
    "To keep data loading consistent across different models, PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data.\n",
    "\n",
    "`Dataset` stores the samples and their corresponding labels. And `DataLoader` wraps an iterable around the Dataset to enable easy access to the samples. More information and examples of the objects in action can be found **[here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)**\n",
    "\n",
    "While Pytorch provides `Dataset` and `Dataloader` for some popular datasets (i.e., one can instantiate the objects and the data is ready to be analyzed in PyTorch Machine Learning pipeline), sometimes we need to define our own custom `Dataset` to process our dataset. The list of available built-in datasets PyTorch gave us can be found **[here](https://pytorch.org/vision/stable/datasets.html)**\n",
    "\n",
    "<div>\n",
    "<img src=\"https://s2.loli.net/2023/03/30/yxbP8gXCroO1Y7c.png\", width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "Diagram Reference: [Link](https://www.kaggle.com/code/uvxy1234/cifar-10-implementation-with-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B8ars4-SHS6"
   },
   "source": [
    "Dataset class is defined with 3 components:\n",
    "\n",
    "1.   __init__ : setting up the parameters being used in the class (e.g., `transforms` which corresponds to the transformation being applied)\n",
    "2.   __len__ : so that len(dataset) returns the size of the dataset.\n",
    "3.   __getitem__ to support the indexing such that `dataset[i]` can be used to get `i`ith sample (in our case Image, label pair).\n",
    "\n",
    "To create a custom Dataset object, you would need overide above functions.\n",
    "\n",
    "Documentation for creating custom dataset can be found [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
    "\n",
    "Luckily, as MNIST is a classic image dataset, we do not need to worry about creating custom `Dataset` and `DataLoader` objects since they are all built into the PyTorch when you import that above.\n",
    "\n",
    "Complete the missing code in the two sections below.\n",
    "\n",
    "*   **1.1.1 Instantiate Train and Test Dataset.** $\\to$ Load and transform data such that it is ready to be passed into the model\n",
    "*   **1.1.2 Instantiate Train and Test Dataloader.** $\\to$ Put the data into the iterable such that the model is able to process data in batch from using `DataLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_EYA1pQSHS7"
   },
   "source": [
    "### 1.1.1 Instantiate Dataset (for train/test dataset) (6 points)\n",
    "\n",
    "One optional argument in Dataset class is `transform`, where we can apply a transformation to the train dataset before we load them as a dataloader.\n",
    "\n",
    "For example if we define a `Resize` function in transform, all of our dataset(images) would be resized to specified size passed in as an argument.\n",
    "\n",
    "---\n",
    "**TODO**: complete the code to apply following transformations (in order!!) by using `transforms.Compose` and save it to the variable `transform`:\n",
    "\n",
    "1.   Resize the image to 28 by 28 $\\to$ just to make sure they are really have size $28$x$28$\n",
    "2.   Convert the images to Tensor\n",
    "3.   Rotate the image using `RandomRotation` with the range of rotation between $(-45°,45°)$\n",
    "4.   Add random perspective shift using `RandomPerspective` with the distortion of `0.3` to `50%` of the data.\n",
    "5.   Normalize the Tensor using mean value of `0.1307` and standard deviation value of `0.3081`\n",
    "---\n",
    "**NOTE**: We highly recommend looking at [PyTorch documentation](https://pytorch.org/vision/stable/transforms.html) and some [illustrations](https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py) before proceeding with the code\n",
    "\n",
    "Please review the the recitation notebook for detailed instructions on how to perform these operations.\n",
    "\n",
    "**FYI**: The values `0.1307` and `0.3081` are mean and standard deviation, respectively, of the MNIST dataset [Ref](https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/4)\n",
    "\n",
    "**NOTE**: Please store the distortion of image in the variable `distortion_scale` since it will be used as an input into the autograder.\n",
    "\n",
    "---\n",
    "**TODO**:\n",
    "\n",
    "Similarly, choose the right transforms and apply them to the test dataset. When applying transforms to test set, we don't apply the ones responsible for data augmentation. Which ones of the transforms that we applied on the training data are for data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3mN0QNRSHS7"
   },
   "outputs": [],
   "source": [
    "scale = 28\n",
    "\n",
    "# # TODO - Define transforms for train set (Remember to store the value of distortion scale in 'distortion_scale' variable)\n",
    "\n",
    "\n",
    "# TODO END\n",
    "\n",
    "\n",
    "# TODO - Define transforms for test set\n",
    "\n",
    "\n",
    "# TODO END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xky6_3jSHS7"
   },
   "source": [
    "Now that we have defined the tranforms we are going to apply to the dataset, let's instantiate `Dataset` objects for both the training and testing sets using predefined PyTorch Dataset. Refer to the documentation [here](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html).\n",
    "\n",
    "In addition, since the whole dataset is pretty large for running the model, we will also be downsampling by reducing the size of the dataset by half.\n",
    "\n",
    "---\n",
    "**TODO**:\n",
    "* Initiate the Dataset object for the training set as `train_dataset`\n",
    "* Downsample training by getting the train data at even-numbered indices, specified as `train_subset`\n",
    "* Initiate the Dataset object for the testing set as `test_dataset`\n",
    "* Downsample `test_dataset` by getting the test data at even-numbered indices, specified as `test_subset`\n",
    "---\n",
    "---\n",
    "\n",
    "**Hint**: Check out [`torch.utils.data.Subset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) for downsampling the dataset.\n",
    "\n",
    "**Note**: When initiating the `Dataset` object for both training and testing sets, in addition to other arguments please set these arguments as follows:\n",
    "* `root = './data'`\n",
    "* `download = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mp6MJPMySHS8"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# TODO END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2rftZmpdMK0"
   },
   "source": [
    "**NOTE**: Please do not forget to store the distortion of image in the variable `distortion_scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wu9vZX8SHS8"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (6 points)\n",
    "transforms_train = []\n",
    "for i in range(len(train_dataset.transform.transforms)):\n",
    "  transforms_train.append(str(train_dataset.transform.transforms[i]))\n",
    "transforms_test = []\n",
    "for i in range(len(test_dataset.transform.transforms)):\n",
    "  transforms_test.append(str(test_dataset.transform.transforms[i]))\n",
    "grader.grade(test_case_id = 'instantiate_dataset', answer = (transforms_train, transforms_test, len(train_subset), len(test_subset), distortion_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9St9G6QalnXV"
   },
   "source": [
    "**Hint:** For the above grader cell, part of the criterias we are checking is if the **transform** object is set up correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMB-Cy3TSHS8"
   },
   "source": [
    "### 1.1.2 Dataloader - Train / Test (4 points)\n",
    "\n",
    "Now that we have `train_subset` and `test_subset`, let's create dataloaders using these two datasets.\n",
    "\n",
    "You can load the dataset into dataloaders using the `DataLoaders` object. Please refer to the documentation [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "---\n",
    "**TODO**:\n",
    "* Initialize the `DataLoader` object for `train_subset` as `train_loader`\n",
    "* Initialize the `DataLoader` object for `test_subset` as `test_loader`\n",
    "---\n",
    "\n",
    "**NOTE**: set the `batch_size` equal to the previously-defined variable `batch`, set `shuffle` to `True`, and `num_workers` as 0.\n",
    "\n",
    "**SHUFFLE**: Do you think shuffling is necessary on test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOzRzIRwSHS9"
   },
   "outputs": [],
   "source": [
    "batch = 64\n",
    "# TODO\n",
    "\n",
    "# TODO END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4xkncSeSHS9"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (4 points)\n",
    "trainLoaderCheck = [getattr(train_loader, \"batch_size\"),\n",
    "                    str(type(train_loader)),\n",
    "                    len(getattr(train_loader, \"dataset\")),\n",
    "                    str(getattr(train_loader, \"sampler\")),\n",
    "                    getattr(train_loader, \"num_workers\")]\n",
    "testLoaderCheck = [getattr(test_loader, \"batch_size\"),\n",
    "                    str(type(test_loader)),\n",
    "                    len(getattr(test_loader, \"dataset\")),\n",
    "                    str(getattr(test_loader, \"sampler\")),\n",
    "                    getattr(test_loader, \"num_workers\")]\n",
    "grader.grade(test_case_id = 'check_dataloader', answer = (trainLoaderCheck, testLoaderCheck))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Vub3boSNj-"
   },
   "source": [
    "## 1.2 Summarizing our Dataset (Total: 10 points)\n",
    "\n",
    "Getting a good sense of the dataset we are going to work on is always the first step you should take when implementing ML applications.\n",
    "\n",
    "In this section, we will be looking at the distribution of the dataset (e.g., how many instances belong to class with label `0`) and visualize what we are dealing with (i.e., plot out the sample images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-FMAUdWSNj_"
   },
   "source": [
    "### 1.2.1 Looking at the distribution of labels (6 points)\n",
    "\n",
    "We can look at the distribution of labels by retrieving the labels of all possible instances of the subset of data pulled from `train_dataset` and `test_dataset` (i.e., `train_subset` and `test_subset`) for the training and testing data, respectively. We defined this in section `1.1.1`.\n",
    "\n",
    "---\n",
    "**TODO**\n",
    "* Train\n",
    "  * Get the number of unique labels in `train_subset` and save this quantity as the variable `train_num_labels`.\n",
    "  * Create a `DataLoader` called `train_loader_bar_plot` which takes as arguments the `train_subset`, with the following parameters:\n",
    "    * `batch_size` = length of the `train_subset`\n",
    "    * `num_workers = 0`\n",
    "  * Create a dictionary `train_subset_dict` that contains the labels as keys and the number of images inside the label as values.\n",
    "* Test\n",
    "  * Get the number of unique labels in testing dataset and save this quantity as the variable `test_num_labels`.\n",
    "  * Create a `DataLoader` called `test_loader_bar_plot` which takes as arguments the `test_subset`,  with the following parameters:\n",
    "    * `batch_size` = length of the `test_subset`\n",
    "    * `num_workers = 0`\n",
    "  * Create a dictionary `test_subset_dict` that contains the labels as keys and the number of images inside the label as values.\n",
    "---\n",
    "Please refer to **[this](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)** for instantiating the `DataLoader`, which is similar to what we did in section `1.1.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3Wo6ww4SNj_"
   },
   "outputs": [],
   "source": [
    "# TODO - TRAIN Data\n",
    "\n",
    "# Use the original train dataset (with 60,000 images) object to obtain the number of label classes train data\n",
    "\n",
    "\n",
    "# Creating dictionary for train dataset\n",
    "\n",
    "# END TODO\n",
    "\n",
    "print(train_subset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwFKDQBzSNkA"
   },
   "outputs": [],
   "source": [
    "# TODO - TEST Data\n",
    "\n",
    "# Use the original test dataset (with 10,000 images) object to obtain the number of label classes in test data\n",
    "\n",
    "\n",
    "# Creating dictionary for test dataset\n",
    "\n",
    "# END TODO\n",
    "print(test_subset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzUrOA8ESNkA"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (6 points)\n",
    "grader.grade(test_case_id = 'dataset_dict', answer = (train_num_labels, train_subset_dict, test_num_labels, test_subset_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qy4qmuuSNkA"
   },
   "source": [
    "### 1.2.2 Visualize through bar charts (2 points - Manual Grading)\n",
    "\n",
    "Now we are going to visualize the distribution of labels using bar charts for both training and testing set which we store the distributions in their respective dictionary objects in section 1.2.1.\n",
    "\n",
    "---\n",
    "**TODO: You can use either `matplotlib` or `seaborn` for this section**\n",
    "* Create a barplot for the distributions of training labels using `train_subset_dict` with x-axis label as `Labels` and y-axis label as `Frequency`, and title as `Training set labels and corresponding frequencies`\n",
    "* Create a barplot for the distributions of testing labels using `test_subset_dict` with x-axis label as `Labels` and y-axis label as `Frequency`, and title as `Testing set labels and corresponding frequencies`\n",
    "* Add corresponding `count labels` to the barplots (i.e., if label 1 has a\n",
    "count of 1200, \"1200\" should appear above the bar corresponding to label 1)\n",
    "-  To avoid \"File Too Large\" for submission, please set figure size to (8,6).\n",
    "---\n",
    "**NOTE**:\n",
    "\n",
    "* y-axis $\\to$ Number of data points\n",
    "* x-axis $\\to$ The integer value of the labels in the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyzzS8y9SNkA"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a barplot showing the distribution of the dataset\n",
    "# TRAIN Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8pNTb0CSNkB"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a barplot showing the distribution of the dataset\n",
    "# TEST Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZsNFvUzSNkB"
   },
   "source": [
    "### 1.2.3 Visualize the Training Dataset! (2 points - Manual Grading)\n",
    "\n",
    "Since everything tends to make more sense when one could literally see it, we now ask you to visualize the images in the `train_dataset` given a fixed set of indices.\n",
    "\n",
    "---\n",
    "\n",
    "**TODO**\n",
    "* loop through the `train_dataset` using `sample_idxs` (the list of indices provided) using a for-loop\n",
    "* For each iteration of this for-loop:\n",
    "  * Plot the current image in grayscale from `train_dataset` indexed by current element in `sample_idxs` using matplotlib in a $2x3$ subplot (2 rows, 3 columns)\n",
    "  * Assign the title of each image to be their respective labels using `plt.title`\n",
    "  * Hide grid lines and axes tick labels\n",
    "  * To avoid \"File Too Large\" for submission, please set overall figure size to (8,4), not individual image.\n",
    "---\n",
    "**HINT**: use `enumerate` in for-loop initialization and apply the current loop number to the subplot\n",
    "\n",
    "**NOTE 1**: `train_dataset` can be indexed by `train_dataset[index]` and you should play around with the output format to get the image and labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiCn3XnXSNkB"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "sample_idxs = [10, 300, 700, 2708, 5035, 8000] # DO NOT MODIFY\n",
    "\n",
    "# # TODO\n",
    "# loop through the length of tickers and keep track of index\n",
    "\n",
    "\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efWfR1ZFvFGw"
   },
   "source": [
    "# **Part 2:** Classification Models (Total: 79)\n",
    "\n",
    "We now have the data needed to train a multi-class object classifier. We will start simple with a softmax regression classifier as a baseline for our performance, before we move onto more complex neural networks.\n",
    "\n",
    "In this case, we are looking at the remaining part in the pipeline which were grayed out before as follows:\n",
    "\n",
    "<div>\n",
    "<img src=\"https://s2.loli.net/2023/03/30/ZCBFQvkXuoJpI8K.png\", width = \"800\"/>\n",
    "</div>\n",
    "\n",
    "Diagram Reference: [Link](https://www.kaggle.com/code/uvxy1234/cifar-10-implementation-with-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIytVVJbm3Ih"
   },
   "source": [
    "## 2.1 Softmax Regression - Baseline (Total: 15 points)\n",
    "\n",
    "Let's first try solving this problem with a Softmax Regression classifier.\n",
    "\n",
    "[Softmax Regression](https://medium.com/@tpreethi/softmax-regression-93808c02e6ac) is a multi-class extension of the binary Logistic Regression classifier. Contrary to Logistic Regression which outputs a single number as the class probability, Softmax Regression has as many outputs as the number of classes.\n",
    "\n",
    "We will define a Softmax Regression model in Pytorch and train it on our training set and evaluate the performance on the test set.\n",
    "\n",
    "Softmax Regression can be modelled as a function that can take in any number of inputs and give outputs for how likely for a sample is to belong to each class for our classification task.\n",
    "\n",
    "Similar to a [Sigmoid activation](https://en.wikipedia.org/wiki/Sigmoid_function) in Logistic Regression, a [Softmax Classifier](https://en.wikipedia.org/wiki/Softmax_function) applies the Softmax function on the model output to give class probabilities for all the classes.\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "In PyTorch, when the [Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), is calculate it applies a softmax function on the output by default, so you don't need to explicitly apply softmax inside your model definition!\n",
    "\n",
    "<div>\n",
    "<img src='https://miro.medium.com/v2/resize:fit:4800/format:webp/1*xjIHYMcUlrGsdaxq9FDJxA.png',width='600'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MFlH2eL9NJ2"
   },
   "source": [
    "Diagram Reference: [Link](https://medium.com/@lomashbhuva/softmax-regression-a-comprehensive-guide-to-multi-class-classification-491202552135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cVmxiP0m3In"
   },
   "source": [
    "### 2.1.1 Softmax Regression Model Architecture (5 points)\n",
    "\n",
    "We will define our first model in Pytorch. Read up about how to define and use layers in a Pytorch neural network [here](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html).\n",
    "\n",
    "Our first model is a softmax regression model with the number of outputs equal to the number of classes in the model. Please implement the constructor for the `SoftmaxReg` class (the `__init__` function below) with the definition of the softmax regression model.\n",
    "\n",
    "**NOTE**: When trying to reshape the features, use the appropriate PyTorch layer instead of tensor reshape/view methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vIXliDkm3Io"
   },
   "outputs": [],
   "source": [
    "class SoftmaxReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: initialize the neural network layers\n",
    "\n",
    "        # END TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: implement the operations on input data\n",
    "\n",
    "        # END TODO\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd5MCDQtm3Ip"
   },
   "source": [
    "Let's print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkIy0N4Wm3Iq"
   },
   "outputs": [],
   "source": [
    "SoftmaxReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDks46ZVm3Ir"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (5 points)\n",
    "grader.grade(test_case_id = 'softmax_regression_model', answer = str(SoftmaxReg()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeRosrvOpGBj"
   },
   "source": [
    "**Notes:** Getting full credit for the above test case doesn't necessarily ensure that your model will perform well on the test dataset as it only evaluates the structure of your neural network.\n",
    "\n",
    "If you don't achieve complete credit for accuracy and loss on the test dataset, you may need to modify your architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jesvQ9qBm3Ir"
   },
   "source": [
    "### 2.1.2 Training Softmax Regression Model (6 points)\n",
    "---\n",
    "**TODOs:**\n",
    "1.   Instantiate the Softmax Regression to the variable `softmaxreg`. Make sure to send this to the GPU device -- please consult the [Module 20 slides](https://docs.google.com/presentation/d/1pw9cFO30U_kI47JUZIW9COLAkM8BE8wr/edit?usp=sharing&ouid=115607071793138372214&rtpof=true&sd=true) for a primer on how to do this.\n",
    "\n",
    "2.   Set the loss criterion as `CrossEntropyLoss` (you can look up the documentation [here](https://pytorch.org/docs/stable/nn.html#loss-functions)). Note that softmax is already built into CrossEntropyLoss so if you use CrossEntropyLoss as the loss criterion, you don't need to add an additional softmax layer.\n",
    "\n",
    "3.   Fill in the missing parts in the training loop (see `#TODO` comments below)\n",
    "4.   Save the Training Accuracy for every epoch into the variable `acc_LIST_soft`.\n",
    "5.   Save the Average Loss for every epoch into the variable `loss_LIST_soft`.\n",
    "---\n",
    "We will use `train_loader` built in 1.1.2 to train Softmax Regression model.\n",
    "\n",
    "The optimizer is set as Adam -- **please do not modify the optimizer**.\n",
    "\n",
    "Hint: Remember to update the weights correctly by backpropagation, please zero out the gradients by calling `optimizer.zero_grad()` every time you call `backward()`.\n",
    "\n",
    "**Note: If the loss went up during the training, there is something wrong with the model, so you should check if the model is implemented correctly**\n",
    "\n",
    "Note: `acc_LIST_soft` and `loss_LIST_soft` should contain data of type float not tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmdlh86xm3Ir"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sending the data to device (CPU or GPU)\n",
    "# TODO: (1 of 2)\n",
    "# Step 1: instantiate the Softmax Regression to variable softmaxreg\n",
    "\n",
    "# Step 2: set the loss criterion as CrossEntropyLoss\n",
    "\n",
    "# END TODO\n",
    "optimizer = optim.Adam(softmaxreg.parameters(), lr=1e-4) #lr - learning step\n",
    "epoch = 10\n",
    "\n",
    "loss_LIST_soft = []\n",
    "acc_LIST_soft = []\n",
    "\n",
    "# Train the Softmax Regression\n",
    "for epoch in range(epoch):\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for inputs, labels in train_loader:\n",
    "      labels = labels.type(torch.LongTensor) # Cast to Float\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      ## TODO (2 of 2)\n",
    "      # Step 1: Reset the optimizer tensor gradient every mini-batch\n",
    "\n",
    "      # Step 2: Feed the network the train data\n",
    "\n",
    "      # Step 3: Get the prediction using argmax\n",
    "\n",
    "      # Step 4: Find average loss for one mini-batch of inputs\n",
    "\n",
    "      # Step 5: Do a back propagation\n",
    "\n",
    "      # Step 6: Update the weight using the gradients from back propagation by learning step\n",
    "\n",
    "      # Step 7: Get loss and add to accumulated loss for each epoch\n",
    "\n",
    "      # Step 8: Get number of correct prediction and increment the number of correct and total predictions after this batch\n",
    "      # Hint: we need to detach the numbers from GPU to CPU, which stores accuracy and loss\n",
    "\n",
    "  # Step 9: Calculate training accuracy for each epoch (should multiply by 100 to get percentage), store in variable called 'accuracy', and add to acc_LIST_soft\n",
    "\n",
    "  # Step 10: Get average loss for each epoch and add to loss_LIST_soft\n",
    "\n",
    "  # END TODO\n",
    "\n",
    "  # print statistics\n",
    "  print(\"The loss for Epoch {} is: {}, Accuracy = {}\".format(epoch, round(running_loss/len(train_loader), 4), round(accuracy, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SB9RkZLJj1qm"
   },
   "outputs": [],
   "source": [
    "# (if applicable)\n",
    "# In order to pass the AutoGrader, every element in \"acc_LIST_soft\" should be a float.\n",
    "# If the elements are of type \"Tensor\", convert each element into type FLOAT by using .item() or .tolist()\n",
    "# To check if each element is a Tensor, print out \"acc_LIST_soft\" and see if there is a Tensor() wrapped around each element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8a3mQpqtFqd6"
   },
   "outputs": [],
   "source": [
    "# Grader Cell (6 points)\n",
    "grader.grade(test_case_id = 'soft_train_loss', answer = (acc_LIST_soft, loss_LIST_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0LrNmOvm3Is"
   },
   "source": [
    "### 2.1.3 Plotting Training Accuracy vs Epochs for Softmax Regression (2 points - Manually Graded)\n",
    "\n",
    "---\n",
    "**TODO:**\n",
    "\n",
    "Plot the training accuracy vs epochs.\n",
    "\n",
    "Chart Specifications:\n",
    "1. The accuracy should be in the y-axis and epochs in x-axis.\n",
    "2. Add chart title.\n",
    "3. Epoch label should start with 1 (for audience interpretability).\n",
    "4. To avoid \"File Too Large\" for submission, please set figure size to (5,3).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VpyKMjem3Is"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TODO\n",
    "\n",
    "# END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrJ6qz4Rm3It"
   },
   "source": [
    "### 2.1.4 Softmax Regression Model Accuracy (2 points)\n",
    "\n",
    "Calculate the Test Accuracy for the Softmax Regression Model we trained above.\n",
    "\n",
    "This should be similar to how we calculated training accuracy above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbAYsblXm3It"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.type(torch.LongTensor) # Cast to Float\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # TODO\n",
    "        # Get the output\n",
    "\n",
    "        # Get the prediction using argmax\n",
    "\n",
    "        # Get number of correct prediction and add to correct and total\n",
    "\n",
    "# Calculate test accuracy for softmax regression (should multiple by 100)\n",
    "# NOTE: Please convert the tensor to a float using .item() and store it as a float\n",
    "test_acc_soft =\n",
    "\n",
    "# TODO END\n",
    "print('Test Accuracy: ' + str(test_acc_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yw84YwDSm3Iu"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (2 points)\n",
    "grader.grade(test_case_id = 'softmax_regression_test_acc', answer = test_acc_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YxGiHhWHM6b"
   },
   "source": [
    "## 2.2 Feedforward Neural Networks (Total: 25 points)\n",
    "\n",
    "<div>\n",
    "<img src='https://s2.loli.net/2022/11/21/dvqstVUzcQPChD1.png', width='400'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCEd-Lj_9pGc"
   },
   "source": [
    "Diagram reference: [Link](https://en.wikipedia.org/wiki/Feedforward_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycezEPcWm3Iv"
   },
   "source": [
    "Since softmax regression isn't that great at the classification problem above, we need more representation power in our model. We will now define a feedforward neural network.\n",
    "\n",
    "Complete the *FNN* class below to define a feedforward neural network with **only 1 hidden layers with ```out_features``` of 256**. Note that the last layer must have the same number of classes as the output size!\n",
    "\n",
    "When implementing this model, please think about what activation function would be most appropriate for each layer in this classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfbU0GmSm3Iv"
   },
   "source": [
    "### 2.2.1 Feedforward Neural Network Model Architecture (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZVvgyJVm3Iv"
   },
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: initialize the neural network layers\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: implement the operations on input data\n",
    "        # Hint: think of the neural network architecture for FNN\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rvgkSaTm3Iw"
   },
   "source": [
    "Let's print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8Voqj1-m3Iw"
   },
   "outputs": [],
   "source": [
    "FNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fj0GVHf5m3Iw"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (10 points)\n",
    "grader.grade(test_case_id = 'feedforward_nn_model', answer = str(FNN()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy7YoUqmurFM"
   },
   "source": [
    "**Notes:** Getting full credit for the above test case doesn't necessarily ensure that your model will perform well on the test dataset as it only evaluates the structure of your neural network.\n",
    "\n",
    "If you don't achieve complete credit for accuracy and loss on the test dataset, you may need to modify your architecture such as increasing the number of hidden layers or the number of neurons in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUaHAHLum3Iw"
   },
   "source": [
    "### 2.2.2 Training FNN Model (11 points)\n",
    "---\n",
    "TODOs\n",
    "1.   Instantiate the FNN to the variable `fnn` (make sure to send this to the device env)\n",
    "2.   Set the loss criterion to be `CrossEntropyLoss` (you can look up the documentation [here](https://pytorch.org/docs/stable/nn.html#loss-functions))\n",
    "3.   Fill in the missing parts in the training loop below.\n",
    "4.   Save the Training Accuracy for every epoch into `acc_LIST_FNN`\n",
    "5.   Save the Average Loss for every epoch into `loss_LIST_FNN`\n",
    "---\n",
    "The optimizer is set as Adam -- **please do not modify the optimizer**.\n",
    "\n",
    "Hint: Remember to update the weights correctly by backpropagation, please zero out the gradients by calling `optimizer.zero_grad()` every time you call `backward()`.\n",
    "\n",
    "**Note: If the loss went up during the training, there is something wrong with the model, so you should check if the model is implemented correctly**\n",
    "\n",
    "The following code bloack should take around 4-5 minutes to complete.\n",
    "\n",
    "Note: `acc_LIST_FNN` and `loss_LIST_FNN` should contain data of type float not tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSechmCnm3Ix"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sending the data to device (CPU or GPU)\n",
    "# TODO (1 of 2)\n",
    "# Step 1: instantiate the FNN model to variable fnn\n",
    "\n",
    "# Step 2: set the loss criterion as CrossEntropyLoss\n",
    "\n",
    "# END TODO\n",
    "optimizer = optim.Adam(fnn.parameters(), lr=1e-4) #lr - learning step\n",
    "epoch = 10\n",
    "\n",
    "acc_LIST_FNN = []\n",
    "loss_LIST_FNN = []\n",
    "\n",
    "# Train the FNN\n",
    "for epoch in range(epoch):\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for inputs, labels in train_loader:\n",
    "      labels = labels.type(torch.LongTensor) # Cast to Long\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      ## TODO (2 of 2)\n",
    "      # Step 1: Reset the optimizer tensor gradient every mini-batch\n",
    "\n",
    "      # Step 2: Feed the network the train data\n",
    "\n",
    "      # Step 3: Get the prediction using argmax\n",
    "\n",
    "      # Step 4: Find average loss for one mini-batch of inputs\n",
    "\n",
    "      # Step 5: Do a back propagation\n",
    "\n",
    "      # Step 6: Update the weight using the gradients from back propagation by learning step\n",
    "\n",
    "      # Step 7: Get loss and add to accumulated loss for each epoch\n",
    "\n",
    "      # Step 8: Get number of correct prediction and increment the number of correct and total predictions after this batch\n",
    "      # Hint: we need to detach the numbers from GPU to CPU, which stores accuracy and loss\n",
    "\n",
    "  # Step 9: Calculate training accuracy for each epoch (should multiply by 100 to get percentage), store in variable called 'accuracy', and add to acc_LIST_FNN\n",
    "\n",
    "  # Step 10: Get average loss for each epoch and add to loss_LIST_FNN\n",
    "\n",
    "  # END TODO\n",
    "\n",
    "  # print statistics\n",
    "  print(\"The loss for Epoch {} is: {}, Accuracy = {}\".format(epoch, running_loss/len(train_loader), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4uVb6MTj6ue"
   },
   "outputs": [],
   "source": [
    "# (if applicable)\n",
    "# In order to pass the AutoGrader, every element in \"acc_LIST_FNN\" should be a float.\n",
    "# If the elements are of type \"Tensor\", convert each element into type FLOAT by using .item() or .tolist()\n",
    "# To check if each element is a Tensor, print out \"acc_LIST_FNN\" and see if there is a Tensor() wrapped around each element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2AHGUxHKI1_"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (11 points)\n",
    "grader.grade(test_case_id = 'fnn_train_loss', answer = (acc_LIST_FNN, loss_LIST_FNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY0zMmGAm3Ix"
   },
   "source": [
    "### 2.2.3 Plotting Training Accuracy vs Epochs FNN (2 points - Manually Graded)\n",
    "\n",
    "---\n",
    "**TODO:**\n",
    "\n",
    "Plot the training accuracy vs epochs.\n",
    "\n",
    "Chart Specifications:\n",
    "1. The accuracy should be in the y-axis and epochs in x-axis.\n",
    "2. Add chart title.\n",
    "3. Epoch label should start with 1 (for audience interpretability).\n",
    "4. To avoid \"File Too Large\" for submission, please set figure size to (5,3).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIGWgoY3m3Ix"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TODO\n",
    "\n",
    "# END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LCcYIAWm3Iy"
   },
   "source": [
    "### 2.2.4 FNN Model Accuracy(2 points)\n",
    "\n",
    "Calculate the Test Accuracy for the FNN Model we trained above (the technique for doing this is the same as computing the test accuracy for the softmax regression classifier above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAyibXsEm3Iy"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.type(torch.LongTensor) # Cast to Float\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # TODO\n",
    "        # Get the output\n",
    "\n",
    "        # Get the prediction using argmax\n",
    "\n",
    "        # Get number of correct prediction and add to correct and total\n",
    "\n",
    "\n",
    "# Calculate test accuracy for FNN (should multiple by 100)\n",
    "# NOTE: Please convert the tensor to a float using .item() and store it as a float\n",
    "test_acc_FNN =\n",
    "# TODO END\n",
    "\n",
    "print('Test Accuracy: ' + str(test_acc_FNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypTvmlYNm3Iy"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (2 points)\n",
    "grader.grade(test_case_id = 'feedforward_nn_acc', answer = (test_acc_FNN, loss_LIST_FNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gnLzDIWGiYv"
   },
   "source": [
    "##2.3 \"Convoluted\" Convolutional Neural Networks (Total: 29 points)\n",
    "So, what are CNNs?\n",
    "\n",
    "Convolutional Neural Networks are very similar to Feedforward Neural Networks from the previous section: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other.\n",
    "\n",
    "So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.\n",
    "\n",
    "If you wanna know more about how CNNs function and see some cool visualizations, we would highly recommend this [page](https://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "<div>\n",
    "<img src='https://s2.loli.net/2022/11/21/L6pUz2chXWRGn31.png', width='800'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQoCe9-I-juy"
   },
   "source": [
    "Diagram Reference: [Link](https://www.analyticsvidhya.com/blog/2020/10/what-is-the-convolutional-neural-network-architecture/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrflHaqht5dV"
   },
   "source": [
    "We will define the architecture for the CNN we will be using. The components of a CNNs are as follows:\n",
    "\n",
    "*   Convolutional Layers\n",
    "*   Pooling Layers\n",
    "*   Linear Layers\n",
    "*   Activation Functions\n",
    "\n",
    "Define a CNN model with Pytorch that contains one or more blocks, where **each block** consists of a **convolutional layer** followed by an **activation function** and a **max pool**. (For this assignment, we discourage adding three or more layers.)\n",
    "\n",
    "Then, **flatten** the output from the convolutional layers, and pass it through one or more fully connected or 'dense' layers and activation functions after all but the last layer. Note that the output shape from the last layer must be the same as the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hZ19uCgt5dV"
   },
   "source": [
    "### 2.3.0 Calculating Output Dimensions of Convolution and Pooling Layers (3 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWTpcdqnt5dW"
   },
   "source": [
    "Before we start building the architecture, it's important to understand the dimensions of the feature maps produced in each of the convolution and pooling layers. We want to keep track of this information as once we get to the fully-connected layers, we need to specify the number of input parameters.\n",
    "\n",
    "Let's first build a function that will help us calculate the dimensions based on the input parameters.\n",
    "\n",
    "\n",
    "Since we are working with squared image, we will build just one function that can be used to calculate both the H (height) and W (width) of the feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function used to calculate the output dimension of the feature map:\n",
    "\n",
    "$$\n",
    "O = \\left\\lfloor \\frac{I - f + 2p}{s} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `I`: Input size (height or width)\n",
    "- `f`: Filter (kernel) size\n",
    "- `p`: Padding applied on both sides of the input\n",
    "- `s`: Stride (default = 1)\n",
    "- $\\lfloor . \\rfloor$: Floor operation, which rounds down to the nearest integer.\n",
    "\n",
    "\n",
    "The formula computes how many times the filter fits into the padded input space along that dimension.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MPO8gBqecED"
   },
   "source": [
    "---\n",
    "**TODO:**\n",
    "\n",
    "Build the **feature_map_dim** function, which takes in the following four parameters and return the dimension of the output feature map.\n",
    "\n",
    "- **input_dim**: height/width of the input image\n",
    "\n",
    "- **kernel_size**: size of the convolving kernel (aka. filter)\n",
    "\n",
    "- **padding**: padding added to all four sides of the input in order to preserve the edges/borders\n",
    "\n",
    "- **stride**: Stride of the convolution, or how many shifts per kernel\n",
    "  \n",
    "ROUND DOWN if the result if a fraction.\n",
    "\n",
    "---\n",
    "\n",
    "Notice there is another parameter, \"dilation\", which is the spacing between kernel elements. We have not covered this in class; simply set it to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3drwoLht5dX"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def feature_map_dim(input_dim, padding, kernel_size, stride):\n",
    "  '''\n",
    "  The function takes in the following four parameters and return the dimension of the output feature map.\n",
    "\n",
    "  input_dim: height/width of the input image\n",
    "  kernel_size: size of the convolving kernel (aka. filter)\n",
    "  padding: padding added to all four sides of the input in order to preserve the edges/borders\n",
    "  stride: Stride of the convolution, or how many shifts per kernel\n",
    "\n",
    "  ROUND DOWN if the result if a fraction.\n",
    "\n",
    "  Notice there is another parameter, \"dilation\", which is the spacing between kernel elements. We have not covered this in class; simply set it to 1\n",
    "  '''\n",
    "  ## TODO:\n",
    "\n",
    "\n",
    "  ## END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Mtd0hHTt5dY"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (3 points)\n",
    "grader.grade(test_case_id = 'test_func_feature_map_dim', answer = getsource(feature_map_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCUg46_pt5dY"
   },
   "source": [
    "### 2.3.1 Convolutional Neural Network Model Architecture (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EML6W1oVt5dY"
   },
   "source": [
    "---\n",
    "**TODOs:**\n",
    "\n",
    "`def __init__(self)`::\n",
    "1.  Initialize 1 - 3 `convolutional blocks` (consists of a convolution layer, an activation function, and a Pooling layer)\n",
    "\n",
    "2. `Flatten` the output of the convolution to a tensor\n",
    "\n",
    "3. Initialize 1-3 `fully-connected layers`\n",
    "\n",
    "`def forward(self, x)`:\n",
    "4. Build the `forward` function/path with the layers initialized in `__init__` function.\n",
    "\n",
    "---\n",
    "\n",
    "- **Note 1:** While parameters of convolution layers tend to vary, it is possible to use the same pooling layer and activation function in each block. If you intend to use the same parameters for these two elements, then only 1 pooling layer and 1 activation function needs to be initialized.\n",
    "- **Note 2** : When trying to reshape the features, use the appropriate PyTorch layer instead of tensor reshape/view methods.\n",
    "- **Hint 1**: Use the `feature_map_dim` function, and the input_dim and output_dim comments to help you keep track of the input/output dimensions of each layer\n",
    "- **Hint 2**: The parameters you've calculated is particularly useful for the input dimensions for the linear layer in the first fully-connected layer.\n",
    "- **Hint 3**: Each input is a grey-scaled (1 channel) 28 x 28 image.\n",
    "- **Hint 4**: The final fully-connected layer's output dimension should be the same as the number of classes in our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtjvdlRYt5dZ"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO\n",
    "\n",
    "        # Step 1: Initialize 1 - 3 convolution blocks (consists of a convolution layer, an activation function, a MaxPooling layer)\n",
    "\n",
    "        ## you are encouraged to use the following comments to keep track of the output dimensions\n",
    "        # input dim = __ channels, with image size __ x __\n",
    "        # output dim = __ channels, with image size __ x __\n",
    "\n",
    "\n",
    "        # Convolution Block 1\n",
    "\n",
    "        # Convolution Block 2 ... Feel free to add 1 - 2 more convolution blocks\n",
    "\n",
    "        # Step 2: Flatten the 2D image into a 1D tensor\n",
    "\n",
    "\n",
    "        # Step 3: Initialize 1-3 fully-connected layers\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "\n",
    "        # Step 1. Pass the images (x) through convolution block 1 and (block 2, 3 if you have built them)\n",
    "\n",
    "\n",
    "        # Step 2. Flatten the image\n",
    "\n",
    "\n",
    "        # Step 3. Pass the output through the fully-connected layers (remember to include activation function(s))\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyo2eeWQt5dZ"
   },
   "source": [
    "Let's print out the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4Fs6gzjt5dZ"
   },
   "outputs": [],
   "source": [
    "CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lOd4qmEt5da"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (12 points)\n",
    "grader.grade(test_case_id = 'cnn_model', answer = str(CNN()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O2dxIV5t5da"
   },
   "source": [
    "### 2.3.2 Training CNN Model (10 Points)\n",
    "\n",
    "---\n",
    "**TODOs**\n",
    "1.   Instantiate the CNN to the variable `cnn` (make sure to send this to the device env)\n",
    "2.   Set the criterion as a CrossEntropyLoss (you can look up the documentation [here](https://pytorch.org/docs/stable/nn.html#loss-functions))\n",
    "3.   Fill in the missing parts in the training loop.\n",
    "4.   Calculate training accuracy for each epoch (should multiply by 100 to get percentage), store in variable called `accuracy`.\n",
    "5.   Save the Training Accuracy for every epoch into `acc_LIST_CNN`\n",
    "6.   Save the Average Loss for every epoch into `loss_LIST_CNN`\n",
    "\n",
    "**Please do not modify the following set ups: **\n",
    "Optimizer: The optimizer is set as \"Adam\".\n",
    "Epoch: The epoch is set to \"10\".\n",
    "\n",
    "---\n",
    "\n",
    "**Hint:** Remember to update the weights correctly by backpropagation, please zero out the gradients by calling `optimizer.zero_grad()` every time you call `backward()`.  Please review the `Recitation 10` notebook for detailed instructions on how to perform these operations.\n",
    "\n",
    "**Note 1**: If the loss went up during the training, there is something wrong with the model, so you should check if the model is implemented correctly.\n",
    "\n",
    "**Note 2**: Typical training time takes between 5 - 10 mins.\n",
    "\n",
    "**Note 3**: `acc_LIST_CNN` and `loss_LIST_CNN` should contain data of type float not tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lW3e2k4Vt5da"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sending the data to device (CPU or GPU)\n",
    "# TODO (1 of 2)\n",
    "# Step 1: instantiate the CNN model to variable cnn\n",
    "\n",
    "# Step 2: set the loss criterion as CrossEntropyLoss\n",
    "\n",
    "# END TODO\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-4) #lr - learning step\n",
    "epoch = 10\n",
    "\n",
    "acc_LIST_CNN = []\n",
    "loss_LIST_CNN = []\n",
    "\n",
    "# Train the CNN\n",
    "for epoch in range(epoch):\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for inputs, labels in train_loader:\n",
    "      labels = labels.type(torch.LongTensor) # Cast to Float\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      ## TODO (2 of 2)\n",
    "      # Step 1: Reset the optimizer tensor gradient every mini-batch\n",
    "\n",
    "      # Step 2: Feed the network the train data\n",
    "\n",
    "      # Step 3: Get the prediction using argmax\n",
    "\n",
    "      # Step 4: Find average loss for one mini-batch of inputs\n",
    "\n",
    "      # Step 5: Do a back propagation\n",
    "\n",
    "      # Step 6: Update the weight using the gradients from back propagation by learning step\n",
    "\n",
    "      # Step 7: Get loss and add to accumulated loss for each epoch\n",
    "\n",
    "      # Step 8: Get number of correct prediction and increment the number of correct and total predictions after this batch\n",
    "      # Hint: we need to detach the numbers from GPU to CPU, which stores accuracy and loss\n",
    "\n",
    "  # Step 9: Calculate training accuracy for each epoch (should multiply by 100 to get percentage), store in variable called 'accuracy', and add to acc_LIST_CNN\n",
    "\n",
    "  # Step 10: Get average loss for each epoch and add to loss_LIST_CNN\n",
    "\n",
    "  # END TODO\n",
    "\n",
    "  # print statistics\n",
    "  print(\"The loss for Epoch {} is: {}, Accuracy = {}\".format(epoch, running_loss/len(train_loader), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsXvPk9LkBXk"
   },
   "outputs": [],
   "source": [
    "# (if applicable)\n",
    "# In order to pass the AutoGrader, every element in \"acc_LIST_CNN\" should be a float.\n",
    "# If the elements are of type \"Tensor\", convert each element into type FLOAT by using .item() or .tolist()\n",
    "# To check if each element is a Tensor, print out \"acc_LIST_CNN\" and see if there is a Tensor() wrapped around each element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZ9IAUWnnO0o"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (10 points)\n",
    "grader.grade(test_case_id = 'cnn_train_loss', answer = (acc_LIST_CNN, loss_LIST_CNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPowtEwjt5db"
   },
   "source": [
    "### 2.3.3 Plotting Training Accuracy vs Epochs CNN (2 points - Manually Graded)\n",
    "\n",
    "---\n",
    "**TODO:**\n",
    "\n",
    "Plot the training accuracy vs epochs.\n",
    "\n",
    "Chart Specifications:\n",
    "1. The accuracy should be in the y-axis and epochs in x-axis.\n",
    "2. Add chart title.\n",
    "3. Epoch label should start with 1 (for audience interpretability).\n",
    "4. To avoid \"File Too Large\" for submission, please set figure size to (5,3).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBZOYpJJt5db"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TODO\n",
    "\n",
    "\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCBs-UQ0t5db"
   },
   "source": [
    "### 2.3.4 CNN Model Test Accuracy (2 points)\n",
    "\n",
    "---\n",
    "**TODO:**\n",
    "Calculate the Test Accuracy for the CNN Model we trained above. Save it to the variable named `test_acc_CNN`. The technique for doing this is the same as computing the test accuracy for the softmax regression and FNN classifiers above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uG-m_1bt5dc"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.type(torch.LongTensor) # Cast to Float\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # TODO\n",
    "        # Get the output\n",
    "\n",
    "        # Get the prediction using argmax\n",
    "\n",
    "        # Get number of correct prediction and add to correct and total\n",
    "\n",
    "\n",
    "# Calculate test accuracy for CNN (should multiple by 100)\n",
    "# NOTE: Please convert the tensor to a float using .item() and store it as a float\n",
    "test_acc_CNN =\n",
    "# TODO END\n",
    "\n",
    "print(f'Test Accuracy: ' + str(test_acc_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iB5d4N-t5dc"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (2 points)\n",
    "grader.grade(test_case_id = 'cnn_test_acc', answer = (test_acc_CNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zf6YZk3t5dc"
   },
   "source": [
    "## 2.4. Reflection (2 point - Manually Graded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNLaEserlayE"
   },
   "source": [
    "\n",
    "Let's compare the model performance:\n",
    "\n",
    "From the test accuracies, we can see that FNN works better than Softmax Regression, and CNN works even better than FNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZCBqWa6lJSb"
   },
   "outputs": [],
   "source": [
    "# Simply run this cell, please do not modify\n",
    "print(f'Test Accuracy for Softmax Regression: ' + str(test_acc_soft))\n",
    "print(f'Test Accuracy for FNN: ' + str(test_acc_FNN))\n",
    "print(f'Test Accuracy for CNN: ' + str(test_acc_CNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOn_Yn3R_qWE"
   },
   "source": [
    "---\n",
    "**TODO:**\n",
    "\n",
    "Now that you've build an image classification model on a relatively simple dataset, could you think of a real-world practical/complex application/use-case where digit recognition is useful?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5u99LTB9jJci"
   },
   "outputs": [],
   "source": [
    "# (Manual Grading - 2 point)\n",
    "\n",
    "# Type your response in the following cell as a comment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVKpT1nRvOP8"
   },
   "source": [
    "## 2.5 Confusion Matrix (Total: 8 points)\n",
    "\n",
    "We want to give you some insight into how you can further analyze the performance of the classification model you have trained.\n",
    "\n",
    "Upto now we have only used accuracy as a measure of performance. Although accuracy is simple and widely used measure, there are drawbacks to using accuracy.\n",
    "\n",
    "Assume that we are trying to train a model to detect a rare disease from CT images of patients. For simplicity, assume that this rare disease has an incidence rate of 1%.\n",
    "\n",
    "In this situation, if we train a degenerative model which always predicts that the patient does not have the disease, the accuracy is very high, namely 99%! Obviously in this case, accuracy is not a good measure of performance of the model.\n",
    "\n",
    "This example serves to motivate confusion matrices and related metrics.\n",
    "\n",
    "A confusion matrix is defined to be $C \\times C$ 2D matrix, where $C$ is number of distinct labels in the dataset. In this matrix, the rows represent the actual labels and the columns represent the predicted labels.\n",
    "\n",
    "The $(i, j)$-th entry of the confusion matrix contains the no. of data points where the actual label is $i$ but the model predicted $j$.\n",
    "\n",
    "<div>\n",
    "<img src='https://s2.loli.net/2023/04/02/7T1e5dtYGihvrRN.png', width='600'>\n",
    "</div>\n",
    "\n",
    "The provided image is an example of a confusion matrix for binary classification (C = 2), but you can easily imagine this scaling up to C > 2.\n",
    "\n",
    "From this confusion matrix we can get all sorts of useful metrics such as False Positive Rate (FPR), False Negative Rate (FNR), Recall, Precision, etc... If you are interested in learning more about confusion matrix and related metrics [this wikipedia page](https://en.wikipedia.org/wiki/Confusion_matrix#cite_note-11) is a good place to look at.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAbFnMXst_7i"
   },
   "source": [
    "### 2.5.1 Create a confusion matrix (4 points)\n",
    "\n",
    "---\n",
    "\n",
    "**TODO:**\n",
    "1. For the test dataset using the CNN model you have trained above, create a confusion matrix.\n",
    "2. Save the confusion matrix as a pandas dataframe called `confusion_matrix_df`.\n",
    "\n",
    "---\n",
    "**Hint:** Look at what you've done in 2.3.4, and see if what you have done can be re-used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the documentation for Scikit-learn's Confusion Matrix method:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "**NOTE**: Remember to always use a trained model to construct your confusion matrix. If you reinitialize your model or restart your notebook without retraining your model, you will get incorrect values for confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVk7BesQt_7j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TODO\n",
    "\n",
    "def cm_generator(test_loader):\n",
    "\n",
    "  # The goal is to obtain two lists of prediction and actual labels.\n",
    "  # Then, using these two lists, create a confusion matrix dataframe\n",
    "\n",
    "\n",
    "# END TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsv-udDgt_7j"
   },
   "outputs": [],
   "source": [
    "#Grader Cell (4 points)\n",
    "import numpy as np\n",
    "grader.grade('check_confusion_matrix', (str(type(confusion_matrix_df)),\n",
    "                                        confusion_matrix_df.shape,\n",
    "                                        confusion_matrix_df.to_numpy().sum(),\n",
    "                                        np.trace(confusion_matrix_df.to_numpy())\n",
    "                                        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfz3myW0t_7k"
   },
   "source": [
    "### 2.5.2 Visualizing Confusion Matrix (4 points - Manual Grading)\n",
    "\n",
    "---\n",
    "**TODOs:**\n",
    "\n",
    "Implement the code to visualize the confusion matrix you have created above. This section will be manually graded\n",
    "\n",
    "Suggested library is using Seaborn heatmap.\n",
    "\n",
    "Chart Specifications:\n",
    "1. Each cell is labled/annotated with associated values. Take a look at the parameter \"annot\".\n",
    "2. Make sure all annotated values are in integers, and not shown in scientific notations. Use the parameter `fmt = \"g\"`.\n",
    "3. Add chart title, and axis name label (\"Actual\" and \"Predicted\". Check out which axis is associated with either label.\n",
    "4. Set map color to Green-Blue (GnBu)\n",
    "5. To avoid \"File Too Large\" for submission, please set figure size to (8,4).\n",
    "---\n",
    "Resource: [Seaborn Heatmap documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMOQnqEAt_7k"
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO\n",
    "\n",
    "\n",
    "# END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXRYkQMgMfQK"
   },
   "source": [
    "# Homework Submission\n",
    "\n",
    "Good job! You have finished the homework :) The submission instructions are as follows:\n",
    "\n",
    "* **Double check** that you have the correct PennID (all numbers) in the autograder.\n",
    "\n",
    "* **Triple check** that you have all plots shown in this Colab notebook before submitting (otherwise, your submission will be subjected to a **penalty of -5 points**).\n",
    "\n",
    "*  Go to the \"File\" tab at the top left of the Colab UI, click \"Download .ipynb\" and then \"Download .py\".  **Rename** these two files to `homework5.ipynb` and `homework5.py` respectively and upload them to Gradescope.\n",
    "  - <ins>**WAIT UNTIL THE GRADESCOPE AUTOGRADER FINISHES RUNNING!**</ins> If we have to manually upload this for you after the deadline, **we will apply a penalty of -5 points** (this stacks with any other penatlies)\n",
    "\n",
    "* You must submit your notebook to receive credit. Post any issues with submission on Ed and make sure to keep in mind the late day policy.\n",
    "\n",
    "* After you submit your code, the teaching staff will manually grade your Colab notebook in order to validate the correctness of your code."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
